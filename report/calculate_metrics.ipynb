{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ambient and attack directories.\n",
      "Loading CAN metadata...\n",
      "Parquet files found...\n",
      "Found processed parquet files...\n",
      "Loading processed parquet files...\n",
      "Loading processing data into 'CANData' structure\n",
      "No attack labels in accelerator_attack_drive_1.log\n",
      "No attack labels in accelerator_attack_drive_2.log\n",
      "No attack labels in accelerator_attack_reverse_1.log\n",
      "No attack labels in accelerator_attack_reverse_2.log\n",
      "Found attack labels in correlated_signal_attack_1.log\n",
      "Found attack labels in correlated_signal_attack_2.log\n",
      "Found attack labels in correlated_signal_attack_3.log\n",
      "Found attack labels in fuzzing_attack_1.log\n",
      "Found attack labels in fuzzing_attack_2.log\n",
      "Found attack labels in fuzzing_attack_3.log\n",
      "Found attack labels in max_engine_coolant_temp_attack.log\n",
      "Found attack labels in max_speedometer_attack_1.log\n",
      "Found attack labels in max_speedometer_attack_2.log\n",
      "Found attack labels in max_speedometer_attack_3.log\n",
      "Found attack labels in reverse_light_off_attack_1.log\n",
      "Found attack labels in reverse_light_off_attack_2.log\n",
      "Found attack labels in reverse_light_off_attack_3.log\n",
      "Found attack labels in reverse_light_on_attack_1.log\n",
      "Found attack labels in reverse_light_on_attack_2.log\n",
      "Found attack labels in reverse_light_on_attack_3.log\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir + \"/code\")\n",
    "\n",
    "from model.CANnoloAttackDetector import CANnoloAttackDetector\n",
    "from data_helpers.CANDataset import CANDataset\n",
    "from helpers import calculate_feature_vec_length, seperate_attack_loader, calculate_metrics\n",
    "from dotenv import load_dotenv\n",
    "# from data_helpers.CANDataLoader import CANDataLoader\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "dataset = CANDataset(data_path, log_verbosity=1)\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"delta_time_last_msg\": {\n",
    "        \"specific_to_can_id\": False,\n",
    "        \"records_back\": 30\n",
    "    },\n",
    "    \"delta_time_last_same_aid\": {\n",
    "        \"specific_to_can_id\": True,\n",
    "        \"records_back\": 15\n",
    "    },\n",
    "}\n",
    "\n",
    "ambient_loader, validation_loader, attack_loader = dataset.get_dataloaders(config)\n",
    "\n",
    "attack_loaders = seperate_attack_loader(attack_loader, config, remove_non_labelled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<data_helpers.CANDataLoader.CANDataLoader at 0x12a3b0b90>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2650>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2710>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b27d0>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2890>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2b54d3010>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b28d0>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2a90>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2b50>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2c10>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2cd0>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2d90>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2e50>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2f10>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b2fd0>,\n",
       " <data_helpers.CANDataLoader.CANDataLoader at 0x2d37b3090>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(attack_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available. Using MPS...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_can_ids = dataset.get_unique_can_ids()\n",
    "num_can_ids = len(unique_can_ids)\n",
    "feature_vec_length = ambient_loader.features_len\n",
    "\n",
    "# Load model\n",
    "model_path = 'models/canolo_model_112.pt'\n",
    "threshold = 6.3e-06\n",
    "\n",
    "model_config = {\n",
    "    \"embedding_dim\": num_can_ids,\n",
    "    \"lstm_units\": 128,\n",
    "    \"dense_units\": 256,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"num_embeddings\": max(unique_can_ids) + 1, # not sure why + 1 rn but it works\n",
    "    \"feature_vec_length\": calculate_feature_vec_length(config)\n",
    "}\n",
    "\n",
    "detector = CANnoloAttackDetector(model_path, threshold, model_config)\n",
    "\n",
    "\n",
    "\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from copy import deepcopy\n",
    "# with ProcessPoolExecutor() as executor:\n",
    "#     # make enought detectors the length of attack_loaders * deep copy\n",
    "#     detectors = [deepcopy(detector) for _ in range(len(attack_loaders))]\n",
    "#     # make a list of tuples of detectors and loaders\n",
    "#     detector_loader_pairs = zip(detectors, attack_loaders)\n",
    "#     # run the detectors in parallel\n",
    "#     results = executor.map(lambda x: calculate_metrics(x[0].detect_attacks(x[1])), detector_loader_pairs)\n",
    "#     # convert the results to a dictionary\n",
    "#     results = dict(zip([loader.can_data[0].filename[0] for loader in attack_loaders], results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector.determine_threshold(ambient_loader)\n",
    "\n",
    "# 0.0000065\n",
    "# 0.0000065\n",
    "# 0.0000065\n",
    "# 0.0000063\n",
    "# 0.000165\n",
    "# .122\n",
    "\n",
    "# ninetyfive_percentile = .0000156\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.threshold = 5.2644566676462956e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on correlated_signal_attack_1.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2381/2382 [00:29<00:00, 80.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9597595548089038, 0.0, 0.0, 0, [[0, 980], [2086, 73126]])\n",
      "Testing on correlated_signal_attack_2.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1729/2043 [00:20<00:03, 86.34it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "meta_results = {}\n",
    "for threshold in [.000095, .000085, .000075, .000065, .000055]:\n",
    "    results = {}\n",
    "    for i, loader in enumerate(attack_loaders):\n",
    "        filename = loader.can_data[0].filename[0]\n",
    "        print(f\"Testing on {filename}\")\n",
    "        results[filename] = calculate_metrics(detector.detect_attacks(loader))\n",
    "        print(results[filename])\n",
    "    meta_results[threshold] = results\n",
    "\n",
    "print(meta_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
