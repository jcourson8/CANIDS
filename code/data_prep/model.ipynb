{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Embedding, Reshape, Concatenate, Flatten, concatenate\n",
    "\n",
    "\n",
    "def create_cannolo_autoencoder(input_features, window_size=40, num_can_ids=100, embedding_size=10):\n",
    "    # Input layers\n",
    "    input_layer = Input(shape=(window_size,))  # Adjust the input shape to be 1D for the embedding layer\n",
    "    can_id_input = Input(shape=(1,), dtype='int32')  # Assuming CAN ID is a single integer\n",
    "\n",
    "    # Embedding for CAN ID\n",
    "    can_id_embedding = Embedding(input_dim=num_can_ids, output_dim=embedding_size, input_length=1)(can_id_input)\n",
    "    can_id_embedding = Reshape(target_shape=(embedding_size,))(can_id_embedding)\n",
    "\n",
    "    # Combine CAN ID embedding with other features\n",
    "    combined_input = Concatenate(axis=-1)([input_layer, can_id_embedding])\n",
    "\n",
    "    # Encoder\n",
    "    encoder = Dense(256, activation='tanh')(input_layer)\n",
    "    encoder = Dropout(0.2)(encoder)\n",
    "    encoder = LSTM(128, return_sequences=True)(encoder)\n",
    "    encoder = LSTM(128, return_sequences=False)(encoder)\n",
    "\n",
    "    # Repeat the encoding\n",
    "    repeater = RepeatVector(window_size)(encoder)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = LSTM(128, return_sequences=True)(repeater)\n",
    "    decoder = LSTM(128, return_sequences=True)(decoder)\n",
    "    output_layer = TimeDistributed(Dense(input_features, activation='sigmoid'))(decoder)\n",
    "\n",
    "    # This creates a model that includes the Input layer and three Dense layers\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cannolo_dense_autoencoder(num_other_features, encoding_dim=128, embedding_size=10):\n",
    "    # # Input layer for CAN IDs\n",
    "    # can_id_input = Input(shape=(1,), dtype='int32', name='can_id_input')\n",
    "    # # Embedding for CAN IDs\n",
    "    # can_id_embedding = Embedding(input_dim=num_can_ids, output_dim=embedding_size, input_length=1, name='can_id_embedding')(can_id_input)\n",
    "    # can_id_embedding = Flatten()(can_id_embedding)\n",
    "\n",
    "    # # Input layer for other features\n",
    "    other_features_input = Input(shape=(num_other_features,), name='other_features_input')\n",
    "\n",
    "    # # Combine CAN ID embedding with other features\n",
    "    # combined = concatenate([can_id_embedding, other_features_input])\n",
    "\n",
    "    # Encoding layers\n",
    "    encoded = Dense(encoding_dim, activation='tanh')(other_features_input)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = Dense(encoding_dim//2, activation='tanh')(encoded)\n",
    "    \n",
    "    # Decoding layers\n",
    "    decoded = Dense(encoding_dim//2, activation='tanh')(encoded)\n",
    "    decoded = Dense(encoding_dim, activation='tanh')(decoded)\n",
    "    \n",
    "    # Output layer for reconstruction\n",
    "    output_layer = Dense(num_other_features, activation='sigmoid', name='output_layer')(decoded)\n",
    "\n",
    "    # This creates a model that includes the input layers and the dense layers\n",
    "    autoencoder = Model(inputs=other_features_input, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ambient and attack directories.\n",
      "Loading CAN metadata...\n",
      "Parquet files found...\n",
      "Found processed parquet files...\n",
      "Loading processed parquet files...\n",
      "Loading processing data into 'CanData' structure\n"
     ]
    }
   ],
   "source": [
    "from CanDataLoader import CanDataLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "data_path = os.getenv('DATA_PATH')\n",
    "dataset = CanDataLoader(data_path, log_verbosity=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 1,\n",
    "    \"delta_time_last_msg\": {\n",
    "        \"specific_to_can_id\": False,\n",
    "        \"records_back\": 30\n",
    "    },\n",
    "    \"delta_time_last_same_aid\": {\n",
    "        \"specific_to_can_id\": True,\n",
    "        \"records_back\": 15\n",
    "    },\n",
    "}\n",
    "\n",
    "ambient_loader, attack_loader = dataset.prepare_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_can_ids = len(dataset.get_unique_can_ids())\n",
    "window_size = ambient_loader.features_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 00:53:48.174163: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-11-10 00:53:48.174184: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-11-10 00:53:48.174193: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-11-10 00:53:48.174228: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-10 00:53:48.174245: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "autoencoder = create_cannolo_dense_autoencoder(num_can_ids,window_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(ambient_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tfEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tfEnv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:901\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         \u001b[39m# The above call may fail if the model is a container-like class\u001b[39;00m\n\u001b[1;32m    896\u001b[0m         \u001b[39m# that does not implement its own forward pass (e.g. a GAN or\u001b[39;00m\n\u001b[1;32m    897\u001b[0m         \u001b[39m# VAE where the forward pass is handled by subcomponents).  Such\u001b[39;00m\n\u001b[1;32m    898\u001b[0m         \u001b[39m# a model does not need to be built.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_batch_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mflatten(peek)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    903\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tensor_spec\u001b[39m(t):\n\u001b[1;32m    904\u001b[0m     \u001b[39m# TODO(b/226395276): Remove _with_tensor_ranks_only usage.\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39mreturn\u001b[39;00m type_spec\u001b[39m.\u001b[39mtype_spec_from_value(t)\u001b[39m.\u001b[39m_with_tensor_ranks_only()\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(ambient_loader, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 23:57:37.146829: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-11-09 23:57:37.146851: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-11-09 23:57:37.146857: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-11-09 23:57:37.147069: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-09 23:57:37.147421: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Assuming we have a determined number of bits for each CAN packet after optimization\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m autoencoder \u001b[39m=\u001b[39m create_cannolo_autoencoder(ambient_loader, window_size, num_can_ids)\n",
      "\u001b[1;32m/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb Cell 5\u001b[0m line \u001b[0;36mcreate_cannolo_autoencoder\u001b[0;34m(input_features, window_size, num_can_ids, embedding_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m encoder \u001b[39m=\u001b[39m Dense(\u001b[39m256\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m)(input_layer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m encoder \u001b[39m=\u001b[39m Dropout(\u001b[39m0.2\u001b[39m)(encoder)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m encoder \u001b[39m=\u001b[39m LSTM(\u001b[39m128\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)(encoder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m encoder \u001b[39m=\u001b[39m LSTM(\u001b[39m128\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)(encoder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jamescourson/Documents/CANIDS/code/data_prep/model.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Repeat the encoding\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tfEnv/lib/python3.10/site-packages/keras/src/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tfEnv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tfEnv/lib/python3.10/site-packages/keras/src/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 256)"
     ]
    }
   ],
   "source": [
    "# Assuming we have a determined number of bits for each CAN packet after optimization\n",
    "autoencoder = create_cannolo_autoencoder(ambient_loader, window_size, num_can_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
